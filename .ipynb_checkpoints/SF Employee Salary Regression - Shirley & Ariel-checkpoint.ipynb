{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The San Francisco Controller's Office maintains a database of the salary and benefits\n",
    "paid to City employees between fiscal years 2013 - 2017.\n",
    "\n",
    "The dataset hosted by the city of San Francisco. The organization has an open data\n",
    "platformÂ and they update their information according the amount of data that is brought\n",
    "in.\n",
    "\n",
    "This dataset is updated annually. New data is added on a bi-annual basis when available\n",
    "for each fiscal and calendar year.\n",
    "\n",
    "The dataset is in csv file: \"employee-compensation.csv\"\n",
    "\n",
    "Our target is to predict the salary.\n",
    "\n",
    "The csv file includes 213K observations and 22 features. After cleaning the Nan's and\n",
    "defining the interested population as employees with total annual salary of at least\n",
    "35,000$, we have almost 150K observations.\n",
    "\n",
    "Three models were selected - Linear Regression, Decision Tree Regressor and Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6aeb7bfcbb04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, OneHotEncoder, KBinsDiscretizer, MaxAbsScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split as split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from time import time\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**\n",
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('employee-compensation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check for missing values (NaN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for nulls\n",
    "print(df.isnull().sum())\n",
    "df[df.Union.isnull() == True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking what are the jobs that have nulls\n",
    "df[df.Union.isnull() == True]['Organization Group'].value_counts()\n",
    "df[df.Union.isnull() == True][df['Organization Group'] == 'Community Health'].Job.value_counts()\n",
    "df[df.Job == 'Technology Expert II'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Visualization**\n",
    "## **Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scatter Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_sm = scatter_matrix(df[['Salaries', 'Total Salary', 'Total Compensation']])\n",
    "#['Salaries', 'Overtime', 'Other Salaries', 'Total Salary', 'Retirement', 'Health/Dental', 'Other Benefits', 'Total Benefits', 'Total Compensation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_sm = scatter_matrix(df[['Retirement', 'Health/Dental', 'Other Benefits', 'Salaries']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(df['Salaries'])\n",
    "ax#.set_xlim(20000,50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Salaries'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = ['Salaries', 'Total Salary', 'Total Compensation']\n",
    "\n",
    "for col in salary:\n",
    "    ax_salary = sns.kdeplot(df[col])\n",
    "    ax_salary#.set_xlim(-25000,75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits = ['Retirement', 'Health/Dental', 'Other Benefits', 'Total Benefits'] \n",
    "\n",
    "for col in benefits:\n",
    "    ax_benefits = sns.kdeplot(df[col])\n",
    "    ax_benefits#.set_xlim(-25000,75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sample the data** \n",
    "### by removing salaries lower than 35,000 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Salaries lower than 35000 \n",
    "df[df['Salaries'] < 35000].count()\n",
    "#ax.set_xlim(20000,50000)\n",
    "#df['Job'][df.Salaries < 0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Salaries'] > 35000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What and how many organizations we are losing by reducing the data to salaries < 35,000$\n",
    "org_x = df[df.Salaries<35000]['Organization Group'].value_counts()\n",
    "org_y = df['Organization Group'].value_counts()\n",
    "org_z = pd.concat([org_x, (org_x/org_y)], axis=1, join='inner', sort=False)\n",
    "org_z.columns = ['Organization Count', 'Organization %']\n",
    "org_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ax = org_z['Organization Count'].plot('bar')\n",
    "for p in org_ax.patches:\n",
    "    org_ax.annotate(int(p.get_height()), (p.get_x(), p.get_height() * 1.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What and how many departments we are losing by reducing the data to salaries < 35,000$\n",
    "dep_x = df[df.Salaries<35000].Department.value_counts()\n",
    "dep_y = df.Department.value_counts()\n",
    "dep_z = pd.concat([dep_x, (dep_x/dep_y)], axis=1, join='inner', sort=False)\n",
    "dep_z.columns = ['Department Count', 'Department %']\n",
    "dep_z.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What and how many jobs we are losing by reducing the data to salaries < 35,000$\n",
    "job_x = df[df.Salaries<35000].Job.value_counts()\n",
    "job_y = df.Job.value_counts()\n",
    "job_z = pd.concat([job_x, (job_x/job_y)], axis=1, join='inner', sort=False)\n",
    "job_z.columns = ['Job Count', 'Job %']\n",
    "job_z.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Continuing with Exploratory Visualization**\n",
    "### ** Distribution of salaries by organizations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for col in list(df2['Organization Group'].unique()):\n",
    "    ax = sns.kdeplot(df2['Salaries'][df2['Organization Group'] == col], label = col)\n",
    "#ax.set_ylim(0,0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Distribution of salaries by years **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for col in list(df2['Year'].unique()):\n",
    "    sns.kdeplot(df2['Salaries'][df2['Year'] == col], label = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Distribution of overtime by organizations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "for col in list(df2['Organization Group'].unique()):\n",
    "    sns.kdeplot(df2['Overtime'][df2['Organization Group'] == col], label = col).set_xlim(-25000,25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Most compensating jobs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_Job = df.groupby('Job').mean()\n",
    "df_groupby_Job['Total Compensation'].sort_values(ascending = False).head(5).plot('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_Job['Total Compensation No Extras'] = df_groupby_Job['Total Compensation'] - df_groupby_Job['Overtime'] - df_groupby_Job['Other Salaries']\n",
    "df_groupby_Job['Total Compensation No Extras'].sort_values(ascending = False).head(5).plot('bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Preprocessing **\n",
    "### ** Replacing sequential features to categorial features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Overtime Amount'] = pd.Series(df2.Overtime / df2.Salaries)\n",
    "#df2['Overtime Amount'].sort_values(ascending = False)#.hist()\n",
    "\n",
    "df2['Overtime Amount'] = pd.cut(df2['Overtime Amount'], 5, labels = ['few overtime', 'less than average overtime', 'average overtime',\n",
    "                                                                     'more than average overtime', 'many overtime'])\n",
    "#df2['Overtime Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Retirement Amount'] = pd.Series(df2.Retirement / df2.Salaries)\n",
    "#df2['Retirement Amount'].sort_values(ascending = False)#.hist()\n",
    "\n",
    "df2['Retirement Amount'] = pd.cut(df2['Retirement Amount'], 5, labels = ['few retirement', 'less than average retirement', 'average retirement',\n",
    "                                                                     'more than average retirement', 'many retirement'])\n",
    "#df2['Retirement Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Health/Dental Amount'] = pd.Series(df2['Health/Dental'] / df2.Salaries)\n",
    "#df2['Health/Dental Amount'].sort_values(ascending = False)#.hist()\n",
    "\n",
    "df2['Health/Dental Amount'] = pd.cut(df2['Health/Dental Amount'], 5, labels = ['few Health/Dental', 'less than average Health/Dental', \n",
    "                                                                               'average Health/Dental', 'more than average Health/Dental', \n",
    "                                                                               'many Health/Dental'])\n",
    "#df2['Health/Dental Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Other Benefits Amount'] = pd.Series(df2['Other Benefits'] / df2.Salaries)\n",
    "#df2['Other Benefits Amount'].sort_values(ascending = False)#.hist()\n",
    "\n",
    "df2['Other Benefits Amount'] = pd.cut(df2['Other Benefits Amount'], 5, labels = ['few Other Benefits', 'less than average Other Benefits', \n",
    "                                                                                 'average Other Benefits', 'more than average Other Benefits', \n",
    "                                                                                 'many Other Benefits'])\n",
    "#df2['Other Benefits Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split features and targets from the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(['Year Type', 'Organization Group', 'Department', 'Union', 'Job Family', 'Job', 'Employee Identifier', 'Salaries', 'Overtime', \n",
    "              'Other Salaries', 'Total Salary', 'Retirement', 'Health/Dental', 'Other Benefits', 'Total Benefits', 'Total Compensation'\n",
    "             ], axis = 1)\n",
    "y = df2.Salaries\n",
    "print(X.shape,\n",
    "      y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training/Predicting Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a pipeline for filling the nulls\n",
    "def get_Job_Family_Code(df):\n",
    "    return df[['Job Family Code']]\n",
    "\n",
    "FullTransformerJobFamilyCode  = Pipeline([(\"Select_Columns\",  FunctionTransformer(func=get_Job_Family_Code, validate=False)),\n",
    "                                          (\"Fill_Null\", SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='No Value')),\n",
    "                                          (\"One_Hot_Encoder\", OneHotEncoder(sparse = False, handle_unknown='ignore'))\n",
    "                                         ])\n",
    "#pd.DataFrame(FullTransformerJobFamilyCode.fit_transform(X[:6950], y[:6950]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a pipeline for filling the nulls\n",
    "def get_features_Union_Code(df):\n",
    "    return df[['Union Code']]\n",
    "\n",
    "FullTransformerUnionCode  = Pipeline([(\"Select_Columns\",  FunctionTransformer(func=get_features_Union_Code, validate=False)),\n",
    "                                      (\"Fill_Null\", SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "                                      (\"One_Hot_Encoder\", OneHotEncoder(sparse = False, handle_unknown='ignore'))\n",
    "                                     ])\n",
    "#pd.DataFrame(FullTransformerUnionCode.fit_transform(X[:6950], y[:6950]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a pipeline for one hot encoding\n",
    "def get_features_onehot(df):\n",
    "    return df.drop(['Union Code', 'Job Family Code'], axis=1)\n",
    "\n",
    "FullTransformerOneHotEncoding  = Pipeline([(\"Select_Columns\",  FunctionTransformer(func=get_features_onehot, validate=False)),\n",
    "                                           (\"One_Hot_Encoder\", OneHotEncoder(sparse = False, handle_unknown='ignore'))])\n",
    "\n",
    "#pd.DataFrame(FullTransformerOneHotEncoding.fit_transform(X[:7000], y[:7000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureUnionTransformer = FeatureUnion([(\"FTJobFamilyCode\",  FullTransformerJobFamilyCode),\n",
    "                                        (\"FTUnionCode\",      FullTransformerUnionCode),\n",
    "                                        (\"FTOneHotEncoding\", FullTransformerOneHotEncoding)\n",
    "                                       ])\n",
    "\n",
    "#pd.DataFrame(FeatureUnionTransformer.fit_transform(X[:7000], y[:7000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction and submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(X, y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear Regression**\n",
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureUnionTransformer.fit_transform(X_train)\n",
    "X_train_transformed = FeatureUnionTransformer.transform(X_train)\n",
    "X_test_transformed = FeatureUnionTransformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train_transformed, y_train, \n",
    "                         scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(scores):\n",
    "    scores_ = (-scores)**0.5\n",
    "    print(scores_)\n",
    "    print(\"Mean:\", scores_.mean())\n",
    "    print(\"Std:\", scores_.std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of train set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr.fit(X_train_transformed, y_train).predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, y_train_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding observation with worst result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (((y_train.values) - y_train_pred)**2).argmax()\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of test set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.fit(X_train_transformed, y_train).predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.xlim(0,500000)\n",
    "plt.ylim(0,500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree Regressor**\n",
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dt, X_train_transformed, y_train, \n",
    "                         scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of train set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = dt.fit(X_train_transformed, y_train).predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, y_train_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of test set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.fit(X_train_transformed, y_train).predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest Regressor**\n",
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=20, n_estimators=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "\n",
    "scores = cross_val_score(rf, X_train_transformed, y_train, \n",
    "                         scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of train set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.fit(X_train_transformed, y_train).predict(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, y_train_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting target of test set and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.fit(X_train_transformed, y_train).predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, y_pred, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II\n",
    "# **Prediction and submission with original data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the nulls\n",
    "df3['Union Code'] = df3['Union Code'].fillna(0)\n",
    "df3[['Union', 'Job Family Code', 'Job Family']] = df3[['Union', 'Job Family Code', 'Job Family']].fillna('No Value')\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummies\n",
    "df3 = pd.get_dummies(df3, columns=['Year', 'Organization Group Code', 'Department Code', 'Union Code', 'Job Family Code', 'Job Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Split features and targets from the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og = df3.drop(['Year Type', 'Organization Group', 'Department', 'Union', 'Job Family', 'Job', 'Employee Identifier', 'Salaries', 'Total Salary',\n",
    "                 'Total Benefits', 'Total Compensation', 'Overtime Amount', 'Retirement Amount', 'Health/Dental Amount', 'Other Benefits Amount'\n",
    "                ], axis = 1)\n",
    "y_og = df3.Salaries\n",
    "print(X_og.shape,\n",
    "      y_og.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_og, X_test_og, y_train_og, y_test_og = split(X_og, y_og)\n",
    "print(X_train_og.shape, y_train_og.shape)\n",
    "print(X_test_og.shape, y_test_og.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train_og, y_train_og, \n",
    "                         scoring='neg_mean_squared_error', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_og = lr.fit(X_train_og, y_train_og).predict(X_train_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train_og, y_train_pred_og, '.', label='Data')\n",
    "plt.plot([0, 400000], [0, 400000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_og = lr.fit(X_train_og, y_train_og).predict(X_test_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_og, y_pred_og, '.', label='Data')\n",
    "plt.plot([0, 400000], [0, 400000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Decision Tree Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "\n",
    "scores = cross_val_score(dt, X_train_og, y_train_og, \n",
    "                         scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_og = dt.fit(X_train_og, y_train_og).predict(X_train_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train_og, y_train_pred_og, '.', label='Data')\n",
    "plt.plot([0, 400000], [0, 400000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_og = dt.fit(X_train_og, y_train_og).predict(X_test_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_og, y_pred_og, '.', label='Data')\n",
    "plt.plot([0, 400000], [0, 400000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=20, n_estimators=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time()\n",
    "\n",
    "scores = cross_val_score(rf, X_train_og, y_train_og, \n",
    "                         scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_og = rf.fit(X_train_og, y_train_og).predict(X_train_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train_og, y_train_pred_og, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_og = rf.fit(X_train_og, y_train_og).predict(X_test_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_og, y_pred_og, '.', label='Data')\n",
    "plt.plot([0, 500000], [0, 500000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best max_depth for DT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def show_results_scores(scores):\n",
    "#    scores_ = (-scores)**0.5\n",
    "#    return scores_.mean()\n",
    "#\n",
    "#t1 = time()\n",
    "#\n",
    "#max_depths = np.linspace(1, 25, 25, endpoint=True)\n",
    "#train_results = []\n",
    "#for max_depth in max_depths:\n",
    "#    dt = DecisionTreeRegressor(max_depth=max_depth)\n",
    "#    # Add score to previous train results\n",
    "#    scores = cross_val_score(dt, X_train_og, y_train_og, scoring='neg_mean_squared_error', cv=10)\n",
    "#    train_results.append(show_results_scores(scores))\n",
    "#print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))\n",
    "#    \n",
    "#from matplotlib.legend_handler import HandlerLine2D\n",
    "#line1, = plt.plot(max_depths, train_results, 'b', label=\"Train Score\")\n",
    "#plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "#plt.ylabel('Score')\n",
    "#plt.xlabel('Tree depth')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = time()\n",
    "#\n",
    "#min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "#train_results = []\n",
    "#for min_samples_split in min_samples_splits:\n",
    "#    dt = DecisionTreeRegressor(min_samples_split=min_samples_split)\n",
    "#    # Add score to previous train results\n",
    "#    scores = cross_val_score(dt, X_train_og, y_train_og, scoring='neg_mean_squared_error', cv=10)\n",
    "#    train_results.append(show_results_scores(scores))\n",
    "#print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))\n",
    "#\n",
    "#from matplotlib.legend_handler import HandlerLine2D\n",
    "#line1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train Score\")\n",
    "#plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "#plt.ylabel('Score')\n",
    "#plt.xlabel('min samples split')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT model - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = time()\n",
    "#dt_gs = GridSearchCV(dt, \n",
    "#                      param_grid={'max_depth': range(1, 21),\n",
    "#                                  'min_samples_split': range(5, 31),                                  \n",
    "#                                  'min_samples_leaf': range(5, 31)},\n",
    "#                      cv=10)\n",
    "#dt_gs.fit(X_train_og, y_train_og)\n",
    "#print (\"Calculation time: {:.2f} [sec]\".format(time()-t1))\n",
    "#print (\"Best parameters:\", dt_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = np.array(df[['Retirement', 'Health/Dental']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.means_\n",
    "gmm.covariances_\n",
    "#gmm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clust[:,0], clust[:,1], s=2, c= gmm.predict(clust))\n",
    "plt.scatter(gmm.means_[:, 0], gmm.means_[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clust[:,0], clust[:,1], s=2, c= gmm.predict(clust))\n",
    "plt.scatter(gmm.means_[:, 0], gmm.means_[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_compensation = np.array(X_og[['Overtime', 'Other Salaries', 'Retirement', 'Health/Dental', 'Other Benefits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_compensation_minmax = MinMaxScaler().fit_transform(clust_compensation)\n",
    "#pd.DataFrame(clust_compensation_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.fit(clust_compensation_minmax)\n",
    "#gmm.predict(clust_compensation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og['Clust Compensation'] = gmm.predict(clust_compensation_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og = pd.get_dummies(X_og, columns=['Clust Compensation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_og.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_og, X_test_og, y_train_og, y_test_og = split(X_og, y_og)\n",
    "print(X_train_og.shape, y_train_og.shape)\n",
    "print(X_test_og.shape, y_test_og.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train_og, y_train_og, \n",
    "                         scoring='neg_mean_squared_error', cv=10)\n",
    "\n",
    "show_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_og = lr.fit(X_train_og, y_train_og).predict(X_train_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train_og, y_train_pred_og, '.', label='Data')\n",
    "plt.plot([0, 400000], [0, 400000], label='Ideal')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
